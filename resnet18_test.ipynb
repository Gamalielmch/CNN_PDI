{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3b028b0-4593-4e7b-8cb9-d1a3e0643438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eb00bb4-2fe9-478c-a94d-a1bcc94f5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "298fb71a-92ca-40da-bcab-bb11efaaf969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28, 1), y=(60000,)\n",
      "Test: X=(10000, 28, 28, 1), y=(10000,)\n",
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testY.shape))\n",
    "pyplot.imshow(trainX[300,:,:,0], cmap='gray')\n",
    "print(trainY[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaacde5f-087f-4fc6-8c9a-cbf5e224b8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "trainY = to_categorical(trainY)\n",
    "testY = to_categorical(testY)\n",
    "print(trainY[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e46d3b6f-4c61-4561-8812-f096e7b1aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from integers to floats\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')\n",
    "# normalize to range 0-1\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23ad5f2b-cdda-469f-b0da-3a4ea3bb89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(Model):\n",
    "    \"\"\"\n",
    "    A standard resnet block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, down_sample=False):\n",
    "        \"\"\"\n",
    "        channels: same as number of convolution kernels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.__channels = channels\n",
    "        self.__down_sample = down_sample\n",
    "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
    "\n",
    "        KERNEL_SIZE = (3, 3)\n",
    "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
    "        INIT_SCHEME = \"he_normal\"\n",
    "\n",
    "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_2 = BatchNormalization()\n",
    "        self.merge = Add()\n",
    "\n",
    "        if self.__down_sample:\n",
    "            # perform down sampling using stride of 2, according to [1].\n",
    "            self.res_conv = Conv2D(\n",
    "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
    "            self.res_bn = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        res = inputs\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "\n",
    "        if self.__down_sample:\n",
    "            res = self.res_conv(res)\n",
    "            res = self.res_bn(res)\n",
    "\n",
    "        # if not perform down sample, then add a shortcut directly\n",
    "        x = self.merge([x, res])\n",
    "        out = tf.nn.relu(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(Model):\n",
    "\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init_bn = BatchNormalization()\n",
    "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res_1_1 = ResnetBlock(64)\n",
    "        self.res_1_2 = ResnetBlock(64)\n",
    "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res_2_2 = ResnetBlock(128)\n",
    "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res_3_2 = ResnetBlock(256)\n",
    "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_4_2 = ResnetBlock(512)\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.flat = Flatten()\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.conv_1(inputs)\n",
    "        out = self.init_bn(out)\n",
    "        out = tf.nn.relu(out)\n",
    "        out = self.pool_2(out)\n",
    "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
    "            out = res_block(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b18da142-7d88-45dc-808b-f0cec0231503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x000001ED35373130>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x000001ED35373130>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"res_net18_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          multiple                  3200      \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  multiple                 256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " resnet_block_9 (ResnetBlock  multiple                 74368     \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_10 (ResnetBloc  multiple                 74368     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_11 (ResnetBloc  multiple                 231296    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_12 (ResnetBloc  multiple                 296192    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_13 (ResnetBloc  multiple                 921344    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_14 (ResnetBloc  multiple                 1182208   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_15 (ResnetBloc  multiple                 3677696   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_16 (ResnetBloc  multiple                 4723712   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " global_average_pooling2d_1   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,189,770\n",
      "Trainable params: 11,180,170\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(10)\n",
    "model.build(input_shape = (None,28,28,1))\n",
    "#use categorical_crossentropy since the label is one-hot encoded\n",
    "opt = SGD(learning_rate=0.001,momentum=0.9, decay=1e-4) #parameters suggested by He [1]\n",
    "model.compile(optimizer = opt,loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3d9e26c-29e8-4bde-a1c6-032cb4d691b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=3):\n",
    "    scores, histories = list(), list()\n",
    "    # prepare cross validation\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(dataX):\n",
    "        # define model\n",
    "        # select rows for train and test\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        # fit model\n",
    "        print(trainX.shape)\n",
    "        history = model.fit(trainX, trainY, epochs=3, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
    "        # evaluate model\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('> %.3f' % (acc * 100.0))\n",
    "        # stores scores\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "    return scores, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafff06c-16bc-46d5-b118-411ecdaa5be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 28, 28, 1)\n",
      "Epoch 1/3\n",
      "1250/1250 [==============================] - 686s 547ms/step - loss: 0.2280 - accuracy: 0.9290 - val_loss: 0.1037 - val_accuracy: 0.9677\n",
      "Epoch 2/3\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9802"
     ]
    }
   ],
   "source": [
    "scores, histories = evaluate_model(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3f1856e-bba5-430c-bf00-c36438eb72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report, precision_recall_fscore_support,ConfusionMatrixDisplay\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "Y_pred = model.predict(testX)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "cm = confusion_matrix(testY, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c206c-806a-47da-aa3c-7e36937fad5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
